{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ3W4H0vcMAegSJvSzIGbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eonlabs-research/rsr-fsa/blob/main/sr_mdd_equity_returns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlJOblahyxND",
        "outputId": "0af27fda-2f82-4b27-fd4f-063941e8a323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.1)\n"
          ]
        }
      ],
      "source": [
        "# CELL BLOCK 01\n",
        "\n",
        "!pip install plotly\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as pyo\n",
        "import plotly.subplots as sp\n",
        "import time\n",
        "from copy import deepcopy\n",
        "from multiprocessing import Pool, Manager"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 02\n",
        "\n",
        "NUM_DAYS = int(28 * 13) * 3\n",
        "# Risk-free rate (annual)\n",
        "ANNUAL_RISK_FREE_RATE = 0.01\n",
        "\n",
        "# Target values for optimization\n",
        "TARGET_SHARPE = 5\n",
        "TARGET_TYPE = \"drawdown\"  # Choose between \"drawdown\" and \"returns\"\n",
        "TARGET_DRAWDOWN = 0.10\n",
        "TARGET_ANNUALIZED_RETURNS = 0.50  # This is an example target if you choose \"returns\" (0.15 means 15% per annum)\n",
        "\n",
        "# Optimization runs\n",
        "NUM_RUNS = 2\n",
        "\n",
        "# Pool's processes\n",
        "pool_processes = 4\n",
        "\n",
        "# PSO Parameters\n",
        "NUM_PARTICLES = 150\n",
        "MAX_ITERATIONS = 400\n",
        "INERTIA = 0.5\n",
        "PERSONAL_BEST_WEIGHT = 1.5\n",
        "GLOBAL_BEST_WEIGHT = 1.5\n",
        "\n",
        "# Dynamic Adjustment Parameters\n",
        "INERTIA_START = 0.9\n",
        "INERTIA_END = 0.4\n",
        "PERSONAL_BEST_START = 2.5\n",
        "PERSONAL_BEST_END = 0.5\n",
        "GLOBAL_BEST_START = 0.5\n",
        "GLOBAL_BEST_END = 2.5\n",
        "\n",
        "# Plotting parameters\n",
        "CHART_HEIGHT = 900\n",
        "\n",
        "# Initialize the Manager and the shared list\n",
        "manager = Manager()\n",
        "strict_results_final = manager.list()\n",
        "print_statements = manager.list()  # Here's our new shared list for print statements!\n"
      ],
      "metadata": {
        "id": "lPhXi0C3Qe9m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 03\n",
        "\n",
        "def calculate_max_drawdown(nav_values):\n",
        "    if np.isnan(nav_values).any() or np.isinf(nav_values).any():\n",
        "        return np.inf\n",
        "    # Safeguard against overflow\n",
        "    safe_nav_values = np.clip(nav_values, -1e10, 1e10)\n",
        "    return np.max(1 - safe_nav_values / np.maximum.accumulate(safe_nav_values))\n",
        "\n",
        "def safe_cumprod(returns):\n",
        "    safe_returns = np.clip(returns + 1, -1e10, 1e10)\n",
        "    return safe_returns.cumprod()\n",
        "\n",
        "def new_sharpe_ratio(returns, annual_rf):\n",
        "    if np.isnan(returns).any() or np.isinf(returns).any():\n",
        "        return -np.inf\n",
        "    excess_returns = returns - annual_rf/365\n",
        "    return np.mean(excess_returns) / np.std(excess_returns, ddof=1) * np.sqrt(365)\n",
        "\n",
        "def has_overlap(equity_curve_1, equity_curve_2, tolerance=1e-5):\n",
        "    \"\"\"Check if two equity curves overlap.\"\"\"\n",
        "    return np.all(np.abs(equity_curve_1 - equity_curve_2) < tolerance)\n"
      ],
      "metadata": {
        "id": "QdXYrlsfQh-C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 04\n",
        "\n",
        "class Particle_v5:\n",
        "    def __init__(self, num_days, annual_rf):\n",
        "        # Adjust the initialization\n",
        "        self.position = np.clip(np.random.normal(annual_rf/365, 0.01, num_days), -0.05, 0.05)  # Random initialization based on NUM_DAYS\n",
        "        # Adjust the velocity range\n",
        "        self.velocity = np.clip(np.random.uniform(-0.01, 0.01, num_days), -0.01, 0.01)\n",
        "        self.best_position = np.copy(self.position)\n",
        "        self.best_score = -np.inf\n",
        "\n",
        "    def update(self, global_best_position, inertia, personal_best_weight, global_best_weight):\n",
        "        inertia_component = inertia * self.velocity\n",
        "        personal_best_component = personal_best_weight * np.random.random() * (self.best_position - self.position)\n",
        "        global_best_component = global_best_weight * np.random.random() * (global_best_position - self.position)\n",
        "        self.velocity = np.clip(inertia_component + personal_best_component + global_best_component, -0.01, 0.01) # Clip velocities again\n",
        "        self.position += self.velocity\n",
        "\n",
        "# Additional parameters to track the best MDD and Cumulative PnL\n",
        "BEST_MDD = manager.Value('d', np.inf)  # 'd' stands for double (i.e., float)\n",
        "BEST_CUMULATIVE_PNL = manager.Value('d', -np.inf)\n",
        "\n",
        "def pso_fitness_function_v2(returns, annual_rf, target_sharpe, target_drawdown):\n",
        "    sharpe = new_sharpe_ratio(returns, annual_rf)\n",
        "    equity_curve = safe_cumprod(returns)\n",
        "    mdd_strict = calculate_max_drawdown(equity_curve)\n",
        "    cumulative_returns = equity_curve[-1]\n",
        "\n",
        "    # Calculating the annualized returns\n",
        "    annualized_returns = (cumulative_returns ** (365.0/len(returns))) - 1\n",
        "\n",
        "    sharpe_penalty = -abs(sharpe - target_sharpe) * 10\n",
        "\n",
        "    # Adjusting the criteria based on the target type\n",
        "    if TARGET_TYPE == \"drawdown\":\n",
        "        # Update the best cumulative PnL if current is lower\n",
        "        global BEST_CUMULATIVE_PNL\n",
        "        if cumulative_returns < BEST_CUMULATIVE_PNL:\n",
        "            BEST_CUMULATIVE_PNL = cumulative_returns\n",
        "        target_penalty = -abs(mdd_strict - target_drawdown) * 10\n",
        "    elif TARGET_TYPE == \"returns\":\n",
        "        # Update the best MDD if current is higher\n",
        "        global BEST_MDD\n",
        "        if mdd_strict > BEST_MDD.value:\n",
        "            BEST_MDD.value = mdd_strict\n",
        "        target_penalty = -abs(annualized_returns - TARGET_ANNUALIZED_RETURNS) * 10\n",
        "\n",
        "    return sharpe_penalty + target_penalty\n",
        "\n",
        "\n",
        "def particle_swarm_optimization_v5(annual_rf, target_sharpe=4, target_drawdown=0.033, num_days=365):\n",
        "    particles = [Particle_v5(num_days, annual_rf) for _ in range(NUM_PARTICLES)]\n",
        "    global_best_position = np.random.normal(annual_rf/365, 0.01, num_days)\n",
        "    global_best_score = -np.inf\n",
        "\n",
        "    # Early Stopping Variables\n",
        "    no_improvement_count = 0\n",
        "    EARLY_STOPPING_THRESHOLD = 50\n",
        "    previous_best = -np.inf\n",
        "\n",
        "    for iteration in range(MAX_ITERATIONS):\n",
        "\n",
        "        # Dynamic adjustments\n",
        "        inertia = INERTIA_START - (iteration/MAX_ITERATIONS) * (INERTIA_START - INERTIA_END)\n",
        "        personal_best_weight = PERSONAL_BEST_START - (iteration/MAX_ITERATIONS) * (PERSONAL_BEST_START - PERSONAL_BEST_END)\n",
        "        global_best_weight = GLOBAL_BEST_START + (iteration/MAX_ITERATIONS) * (GLOBAL_BEST_END - GLOBAL_BEST_START)\n",
        "\n",
        "        for particle in particles:\n",
        "            particle.update(global_best_position, inertia, personal_best_weight, global_best_weight)\n",
        "\n",
        "            fitness = pso_fitness_function_v2(particle.position, annual_rf, target_sharpe, target_drawdown)\n",
        "            if fitness > particle.best_score:\n",
        "                particle.best_score = fitness\n",
        "                particle.best_position = deepcopy(particle.position)\n",
        "            if fitness > global_best_score:\n",
        "                global_best_score = fitness\n",
        "                global_best_position = deepcopy(particle.position)\n",
        "\n",
        "        # Early stopping check\n",
        "        if global_best_score > previous_best:\n",
        "            previous_best = global_best_score\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "\n",
        "        if no_improvement_count >= EARLY_STOPPING_THRESHOLD:\n",
        "            break\n",
        "\n",
        "        for particle in particles:\n",
        "            particle.update(global_best_position, inertia, personal_best_weight, global_best_weight)\n",
        "\n",
        "\n",
        "    return global_best_position, (global_best_position + 1).cumprod()"
      ],
      "metadata": {
        "id": "D9gjo0QXkIRe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 05\n",
        "\n",
        "def diagnostic_run_pso(run_id):\n",
        "    MAX_ATTEMPTS = 10\n",
        "    attempts = 0  # Initialize the 'attempts' variable here\n",
        "\n",
        "    # Now, the for loop to iterate over attempts\n",
        "    for attempt in range(MAX_ATTEMPTS):\n",
        "        print_statements.append(f\"ðŸ¤  Starting PSO for Run ID {run_id+1} - Attempt {attempt+1} of {MAX_ATTEMPTS} ðŸ¤ \")\n",
        "\n",
        "    while attempts < MAX_ATTEMPTS:\n",
        "        returns_strict, equity_curve_strict = particle_swarm_optimization_v5(ANNUAL_RISK_FREE_RATE, TARGET_SHARPE, TARGET_DRAWDOWN, NUM_DAYS)\n",
        "        sharpe_strict = new_sharpe_ratio(returns_strict, ANNUAL_RISK_FREE_RATE)\n",
        "        mdd_strict = calculate_max_drawdown(equity_curve_strict)\n",
        "        cumulative_returns = equity_curve_strict[-1]\n",
        "        annualized_returns = (cumulative_returns ** (365.0/len(returns_strict))) - 1\n",
        "\n",
        "        # Adjusting the criteria based on the target type\n",
        "        if TARGET_TYPE == \"drawdown\":\n",
        "            meets_criteria = (TARGET_SHARPE - 0.1 <= sharpe_strict <= TARGET_SHARPE + 0.1) and (TARGET_DRAWDOWN - 0.002 <= mdd_strict <= TARGET_DRAWDOWN + 0.002)\n",
        "        elif TARGET_TYPE == \"returns\":\n",
        "            meets_criteria = (TARGET_SHARPE - 0.1 <= sharpe_strict <= TARGET_SHARPE + 0.1) and (TARGET_ANNUALIZED_RETURNS - 0.02 <= annualized_returns <= TARGET_ANNUALIZED_RETURNS + 0.02)\n",
        "\n",
        "        # Check for overlap with previous results\n",
        "        overlap = any(has_overlap(equity_curve_strict, previous_curve[1]) for previous_curve in list(strict_results_final))\n",
        "\n",
        "        if meets_criteria and not overlap:\n",
        "            print_statements.append(f\"Found a valid solution on attempt {attempt+1}!\")  # Logging the success\n",
        "            return (returns_strict, equity_curve_strict, sharpe_strict, mdd_strict)\n",
        "\n",
        "        attempts += 1\n",
        "        print_statements.append(f\"Attempt {attempt+1} did not meet criteria.\")\n",
        "\n",
        "    print_statements.append(f\"Exiting after {MAX_ATTEMPTS} attempts without a valid solution.\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "ohvy5fnBQk8O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 05\n",
        "\n",
        "# Begin main execution\n",
        "start_time = time.time()\n",
        "\n",
        "with Pool(processes=pool_processes) as pool:\n",
        "    results = pool.imap(diagnostic_run_pso, range(NUM_RUNS))\n",
        "\n",
        "\n",
        "# Initialize our chest of treasures (a list) to store our unique equity curves\n",
        "strict_results_final = []\n",
        "\n",
        "# Adjusting the main loop based on the feedback\n",
        "while len(strict_results_final) < NUM_RUNS:\n",
        "    # If our target is drawdown, set a new stricter cumulative PnL constraint for the next run\n",
        "    if TARGET_TYPE == \"drawdown\":\n",
        "        TARGET_ANNUALIZED_RETURNS = min(BEST_CUMULATIVE_PNL, TARGET_ANNUALIZED_RETURNS)\n",
        "\n",
        "    # If our target is returns, set a new stricter MDD constraint for the next run\n",
        "    elif TARGET_TYPE == \"returns\":\n",
        "        TARGET_DRAWDOWN = max(BEST_MDD.value, TARGET_DRAWDOWN)\n",
        "\n",
        "    with Pool(processes=4) as pool:\n",
        "        results = pool.map(diagnostic_run_pso, range(NUM_RUNS - len(strict_results_final)))\n",
        "\n",
        "    # Filter out None results and add to our chest of treasures\n",
        "    for res in results:\n",
        "        if res is not None:\n",
        "            overlap = any(has_overlap(res[1], previous_curve[1]) for previous_curve in list(strict_results_final))\n",
        "            if not overlap:\n",
        "                strict_results_final.append(res)\n",
        "\n",
        "success_rate = len(strict_results_final) / NUM_RUNS\n",
        "print_statements.append(f\"Success rate of meeting criteria: {success_rate * 100:.2f}%\")\n",
        "\n",
        "print_statements.append(f\"Time taken: {time.time() - start_time} seconds\")\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Calculate the start date which is NUM_DAYS prior from today\n",
        "start_date = datetime.today() - timedelta(days=NUM_DAYS)\n",
        "\n",
        "# Step 4: Save the aggregated data for each run in the CSV format\n",
        "for i, (returns, equity_curve, _, _) in enumerate(strict_results_final):\n",
        "    data = {\n",
        "        'Date': pd.date_range(start=start_date, periods=NUM_DAYS, freq='D'),\n",
        "        'PnL': returns,\n",
        "        'NAV': equity_curve\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    # Saving to Colab's storage\n",
        "    df.to_csv(f'run_{i+1}_data.csv', index=False)\n",
        "\n",
        "# Step 6: Function to read the saved data from a CSV\n",
        "def read_data_from_csv(run_number):\n",
        "    df = pd.read_csv(f'run_{run_number}_data.csv')\n",
        "    return df['Date'], df['PnL'], df['NAV']\n",
        "\n",
        "# Step 7: Unit Test to validate the read-in data\n",
        "for i in range(NUM_RUNS):\n",
        "    date, pnl, nav = read_data_from_csv(i+1)\n",
        "    original_returns, original_equity_curve, _, _ = strict_results_final[i]\n",
        "    assert np.allclose(pnl, original_returns), f\"Data mismatch for PnL in run {i+1}\"\n",
        "    assert np.allclose(nav, original_equity_curve), f\"Data mismatch for NAV in run {i+1}\"\n",
        "\n",
        "print(\"ðŸš€ Yeehaw! All data is saved and validated successfully. You're good to go, partner!\")\n"
      ],
      "metadata": {
        "id": "VfU5xKA31ON5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 07\n",
        "\n",
        "# Step 8: Function to calculate MDD and Sharpe from the CSV\n",
        "def calculate_metrics_from_csv(run_number):\n",
        "    _, pnl, nav = read_data_from_csv(run_number)\n",
        "\n",
        "    mdd = calculate_max_drawdown(nav)\n",
        "    sharpe = new_sharpe_ratio(pnl, ANNUAL_RISK_FREE_RATE)\n",
        "\n",
        "    return mdd, sharpe\n",
        "\n",
        "\n",
        "# Step 9: Loop through each CSV and calculate metrics\n",
        "for i in range(NUM_RUNS):\n",
        "    mdd, sharpe = calculate_metrics_from_csv(i+1)\n",
        "    print_statements.append(f\"ðŸŒµ For Run {i+1} ðŸŒµ\")\n",
        "    print_statements.append(f\"Max Drawdown: {mdd:.4f}\")\n",
        "    print_statements.append(f\"Sharpe Ratio: {sharpe:.4f}\")\n",
        "    print_statements.append(\"-\" * 40)\n",
        "\n",
        "# Release the Hounds\n",
        "for statement in print_statements:\n",
        "    print(statement)"
      ],
      "metadata": {
        "id": "XUiUro8QkXGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL BLOCK 08\n",
        "\n",
        "fig_strict_final = go.Figure()\n",
        "\n",
        "# Define the buttons for updating the y-axis type\n",
        "buttons = [\n",
        "    dict(args=[{\"yaxis2.type\": \"linear\"}], label=\"Linear\", method=\"relayout\"),\n",
        "    dict(args=[{\"yaxis2.type\": \"log\"}], label=\"Log\", method=\"relayout\")\n",
        "]\n",
        "\n",
        "# Add the equity curve traces\n",
        "for i in range(NUM_RUNS):\n",
        "    date, pnl, nav = read_data_from_csv(i+1)\n",
        "    fig_strict_final.add_trace(\n",
        "        go.Scatter(\n",
        "            x=date,  # We're using the date as the x-values now\n",
        "            y=nav,\n",
        "            mode='lines',\n",
        "            name=f\"Run {i+1}\",\n",
        "            xaxis=\"x2\",\n",
        "            yaxis=\"y2\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Preparing data for the table\n",
        "header_values = [\"PSO Run\", \"Avg Daily PnL\", \"Cumulative PnL\", \"Annualized Sharpe Ratio\", \"Fractional MDD\"]\n",
        "rows = []\n",
        "for i in range(NUM_RUNS):\n",
        "    _, pnl, nav = read_data_from_csv(i+1)\n",
        "    sharpe = new_sharpe_ratio(pnl, ANNUAL_RISK_FREE_RATE)\n",
        "    mdd = calculate_max_drawdown(nav)\n",
        "    rows.append([f\"Run {i+1}\", f\"{np.mean(pnl):.7f}\", f\"{nav.iloc[-1]-1:.7f}\", f\"{sharpe:.7f}\", f\"{mdd:.4f}\"])\n",
        "\n",
        "# Creating a table at the top\n",
        "fig_strict_final.add_trace(\n",
        "    go.Table(\n",
        "        domain=dict(x=[0, 1], y=[0.8, 1]),\n",
        "        header=dict(values=header_values),\n",
        "        cells=dict(values=np.transpose(rows))\n",
        "    )\n",
        ")\n",
        "\n",
        "# Styling the layout\n",
        "fig_strict_final.update_layout(\n",
        "    template=\"plotly_dark\",\n",
        "    title=\"Equity Curves with Parameterized Settings\",\n",
        "    xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Equity Value\",\n",
        "    font=dict(size=15, family='Roboto Mono, monospace'),\n",
        "    hovermode=\"x unified\",\n",
        "    height=CHART_HEIGHT,\n",
        "    xaxis2=dict(anchor=\"y2\", domain=[0, 1]),\n",
        "    yaxis2=dict(anchor=\"x2\", domain=[0, 0.8]),\n",
        "    updatemenus=[\n",
        "        dict(\n",
        "            type=\"buttons\",\n",
        "            showactive=True,\n",
        "            y=0.05,\n",
        "            x=0.95,\n",
        "            xanchor=\"right\",\n",
        "            yanchor=\"bottom\",\n",
        "            buttons=buttons\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig_strict_final.show()\n"
      ],
      "metadata": {
        "id": "ZFNa0yNX0SWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}