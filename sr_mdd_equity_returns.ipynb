{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5PJG/i2PoOLGTPxAaEjaM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eonlabs-research/rsr-fsa/blob/main/sr_mdd_equity_returns.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlJOblahyxND",
        "outputId": "37dd015f-c9a6-48cc-95b8-cf14aeb82a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (23.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install plotly\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as pyo\n",
        "import time\n",
        "from copy import deepcopy\n",
        "from multiprocessing import Pool, Manager"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_DAYS = 1000\n",
        "\n",
        "# PSO Parameters\n",
        "NUM_PARTICLES = 150\n",
        "MAX_ITERATIONS = 400\n",
        "INERTIA = 0.5\n",
        "PERSONAL_BEST_WEIGHT = 1.5\n",
        "GLOBAL_BEST_WEIGHT = 1.5\n",
        "\n",
        "# Target values for optimization\n",
        "TARGET_SHARPE = 3\n",
        "TARGET_DRAWDOWN = 0.20\n",
        "\n",
        "# Risk-free rate (annual)\n",
        "ANNUAL_RISK_FREE_RATE = 0.01\n",
        "\n",
        "# Plotting parameters\n",
        "CHART_HEIGHT = 900\n",
        "\n",
        "# Optimization runs\n",
        "NUM_RUNS = 4\n",
        "\n",
        "# Dynamic Adjustment Parameters\n",
        "INERTIA_START = 0.9\n",
        "INERTIA_END = 0.4\n",
        "PERSONAL_BEST_START = 2.5\n",
        "PERSONAL_BEST_END = 0.5\n",
        "GLOBAL_BEST_START = 0.5\n",
        "GLOBAL_BEST_END = 2.5"
      ],
      "metadata": {
        "id": "lPhXi0C3Qe9m"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_max_drawdown(nav_values):\n",
        "    if np.isnan(nav_values).any() or np.isinf(nav_values).any():\n",
        "        return np.inf\n",
        "    # Safeguard against overflow\n",
        "    safe_nav_values = np.clip(nav_values, -1e10, 1e10)\n",
        "    return np.max(1 - safe_nav_values / np.maximum.accumulate(safe_nav_values))\n",
        "\n",
        "def safe_cumprod(returns):\n",
        "    # Cap the cumulative returns to avoid overflow\n",
        "    capped_returns = np.clip(returns, -0.99, 1e10)\n",
        "    return (capped_returns + 1).cumprod()\n",
        "\n",
        "def new_sharpe_ratio(returns, annual_rf):\n",
        "    if np.isnan(returns).any() or np.isinf(returns).any():\n",
        "        return -np.inf\n",
        "    excess_returns = returns - annual_rf/365\n",
        "    return np.mean(excess_returns) / np.std(excess_returns, ddof=1) * np.sqrt(365)\n",
        "\n",
        "# Particle definition for PSO v5\n",
        "class Particle_v5:\n",
        "    def __init__(self, num_days, annual_rf):\n",
        "        # Adjust the initialization\n",
        "        self.position = np.clip(np.random.normal(annual_rf/365, 0.01, num_days), -0.05, 0.05)  # Random initialization based on NUM_DAYS\n",
        "        # Adjust the velocity range\n",
        "        self.velocity = np.clip(np.random.uniform(-0.01, 0.01, num_days), -0.01, 0.01)\n",
        "        self.best_position = np.copy(self.position)\n",
        "        self.best_score = -np.inf\n",
        "\n",
        "    def update(self, global_best_position, inertia, personal_best_weight, global_best_weight):\n",
        "        inertia_component = inertia * self.velocity\n",
        "        personal_best_component = personal_best_weight * np.random.random() * (self.best_position - self.position)\n",
        "        global_best_component = global_best_weight * np.random.random() * (global_best_position - self.position)\n",
        "        self.velocity = np.clip(inertia_component + personal_best_component + global_best_component, -0.01, 0.01) # Clip velocities again\n",
        "        self.position += self.velocity\n",
        "\n",
        "\n",
        "def safe_cumprod(returns):\n",
        "    safe_returns = np.clip(returns + 1, -1e10, 1e10)\n",
        "    return safe_returns.cumprod()\n",
        "\n",
        "def pso_fitness_function_v2(returns, annual_rf, target_sharpe, target_drawdown):\n",
        "    sharpe = new_sharpe_ratio(returns, annual_rf)\n",
        "    equity_curve = safe_cumprod(returns)\n",
        "    max_drawdown = calculate_max_drawdown(equity_curve)\n",
        "    sharpe_penalty = -abs(sharpe - target_sharpe) * 10\n",
        "    drawdown_penalty = -abs(max_drawdown - target_drawdown) * 10\n",
        "    return sharpe_penalty + drawdown_penalty\n",
        "\n",
        "def particle_swarm_optimization_v5(annual_rf, target_sharpe=4, target_drawdown=0.033, num_days=365):\n",
        "    particles = [Particle_v5(num_days, annual_rf) for _ in range(NUM_PARTICLES)]\n",
        "    global_best_position = np.random.normal(annual_rf/365, 0.01, num_days)\n",
        "    global_best_score = -np.inf\n",
        "\n",
        "    # Early Stopping Variables\n",
        "    no_improvement_count = 0\n",
        "    EARLY_STOPPING_THRESHOLD = 50\n",
        "    previous_best = -np.inf\n",
        "\n",
        "    for iteration in range(MAX_ITERATIONS):\n",
        "\n",
        "        # Dynamic adjustments\n",
        "        inertia = INERTIA_START - (iteration/MAX_ITERATIONS) * (INERTIA_START - INERTIA_END)\n",
        "        personal_best_weight = PERSONAL_BEST_START - (iteration/MAX_ITERATIONS) * (PERSONAL_BEST_START - PERSONAL_BEST_END)\n",
        "        global_best_weight = GLOBAL_BEST_START + (iteration/MAX_ITERATIONS) * (GLOBAL_BEST_END - GLOBAL_BEST_START)\n",
        "\n",
        "        for particle in particles:\n",
        "            particle.update(global_best_position, inertia, personal_best_weight, global_best_weight)\n",
        "\n",
        "            fitness = pso_fitness_function_v2(particle.position, annual_rf, target_sharpe, target_drawdown)\n",
        "            if fitness > particle.best_score:\n",
        "                particle.best_score = fitness\n",
        "                particle.best_position = deepcopy(particle.position)\n",
        "            if fitness > global_best_score:\n",
        "                global_best_score = fitness\n",
        "                global_best_position = deepcopy(particle.position)\n",
        "\n",
        "        # Early stopping check\n",
        "        if global_best_score > previous_best:\n",
        "            previous_best = global_best_score\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "\n",
        "        if no_improvement_count >= EARLY_STOPPING_THRESHOLD:\n",
        "            break\n",
        "\n",
        "        for particle in particles:\n",
        "            particle.update(global_best_position, inertia, personal_best_weight, global_best_weight)\n",
        "\n",
        "\n",
        "    return global_best_position, (global_best_position + 1).cumprod()"
      ],
      "metadata": {
        "id": "QdXYrlsfQh-C"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Step 0: Initialize the Manager and the shared list\n",
        "manager = Manager()\n",
        "strict_results_final = manager.list()\n",
        "\n",
        "# Step 1: Create a function to check for overlap\n",
        "def has_overlap(equity_curve_1, equity_curve_2, tolerance=1e-5):\n",
        "    \"\"\"Check if two equity curves overlap.\"\"\"\n",
        "    return np.all(np.abs(equity_curve_1 - equity_curve_2) < tolerance)\n",
        "\n",
        "# Step 2: Modify diagnostic_run_pso\n",
        "def diagnostic_run_pso(_):\n",
        "    MAX_ATTEMPTS = 5\n",
        "    attempts = 0\n",
        "    while attempts < MAX_ATTEMPTS:\n",
        "        returns_strict, equity_curve_strict = particle_swarm_optimization_v5(ANNUAL_RISK_FREE_RATE, TARGET_SHARPE, TARGET_DRAWDOWN, NUM_DAYS)\n",
        "        sharpe_strict = new_sharpe_ratio(returns_strict, ANNUAL_RISK_FREE_RATE)\n",
        "        mdd_strict = calculate_max_drawdown(equity_curve_strict)\n",
        "        meets_criteria = (TARGET_SHARPE - 0.1 <= sharpe_strict <= TARGET_SHARPE + 0.1) and (TARGET_DRAWDOWN - 0.002 <= mdd_strict <= TARGET_DRAWDOWN + 0.002)\n",
        "\n",
        "        # Check for overlap with previous results\n",
        "        overlap = any(has_overlap(equity_curve_strict, previous_curve[1]) for previous_curve in list(strict_results_final))\n",
        "\n",
        "        if meets_criteria and not overlap:\n",
        "            return (returns_strict, equity_curve_strict, sharpe_strict, mdd_strict)\n",
        "\n",
        "        attempts += 1\n",
        "    return None\n",
        "\n",
        "with Pool(processes=4) as pool:\n",
        "    results = pool.map(diagnostic_run_pso, range(NUM_RUNS))\n",
        "\n",
        "# Initialize our chest of treasures (a list) to store our unique equity curves\n",
        "strict_results_final = []\n",
        "\n",
        "# Adjust the main loop\n",
        "while len(strict_results_final) < NUM_RUNS:\n",
        "    with Pool(processes=4) as pool:\n",
        "        results = pool.map(diagnostic_run_pso, range(NUM_RUNS - len(strict_results_final)))\n",
        "\n",
        "    # Filter out None results and add to our chest of treasures\n",
        "    for res in results:\n",
        "        if res is not None:\n",
        "            overlap = any(has_overlap(res[1], previous_curve[1]) for previous_curve in list(strict_results_final))\n",
        "            if not overlap:\n",
        "                strict_results_final.append(res)\n",
        "\n",
        "success_rate = len(strict_results_final) / NUM_RUNS\n",
        "print(f\"Success rate of meeting criteria: {success_rate * 100:.2f}%\")\n",
        "\n",
        "print(\"Time taken:\", time.time() - start_time, \"seconds\")"
      ],
      "metadata": {
        "id": "ohvy5fnBQk8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_strict_final = go.Figure()\n",
        "\n",
        "# Define the buttons for updating the y-axis type\n",
        "buttons = [\n",
        "    dict(args=[{\"yaxis.type\": \"linear\"}], label=\"Linear\", method=\"relayout\"),\n",
        "    dict(args=[{\"yaxis.type\": \"log\"}], label=\"Log\", method=\"relayout\")\n",
        "]\n",
        "\n",
        "# Adding the equity curve traces\n",
        "for i, (returns, equity_curve, sharpe, mdd) in enumerate(strict_results_final):\n",
        "    fig_strict_final.add_trace(\n",
        "        go.Scatter(\n",
        "            y=equity_curve,\n",
        "            mode='lines',\n",
        "            name=f\"Run {i+1}\",\n",
        "            showlegend=False  # Do not show the regular legend\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Preparing data for the table\n",
        "rows = []\n",
        "header_values = [\"PSO Run\", \"Avg Daily PnL\", \"Cumulative PnL\", \"Annualized Sharpe Ratio\", \"Fractional MDD\"]\n",
        "for i, (returns, equity_curve, sharpe, mdd) in enumerate(strict_results_final):\n",
        "    rows.append([f\"Run {i+1}\", f\"{np.mean(returns):.7f}\", f\"{equity_curve[-1]-1:.7f}\", f\"{sharpe:.7f}\", f\"{mdd:.4f}\"])\n",
        "\n",
        "# Creating a table\n",
        "fig_strict_final.add_trace(\n",
        "    go.FigureWidget(\n",
        "        go.Table(\n",
        "            header=dict(values=header_values),\n",
        "            cells=dict(values=np.transpose(rows))\n",
        "        )\n",
        "    ).data[0]\n",
        ")\n",
        "\n",
        "# Styling the layout\n",
        "fig_strict_final.update_layout(\n",
        "    template=\"plotly_dark\",\n",
        "    title=\"Equity Curves with Parameterized Settings\",\n",
        "    xaxis_title=\"Days\",\n",
        "    yaxis_title=\"Equity Value\",\n",
        "    font=dict(size=15, family='Roboto Mono, monospace'),\n",
        "    hovermode=\"x unified\",\n",
        "    height=CHART_HEIGHT,\n",
        "    updatemenus=[\n",
        "        dict(\n",
        "            type=\"buttons\",\n",
        "            showactive=True,\n",
        "            y=0.05,\n",
        "            x=0.95,\n",
        "            xanchor=\"right\",\n",
        "            yanchor=\"bottom\",\n",
        "            buttons=buttons\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "fig_strict_final.show()\n",
        "\n",
        "\n",
        "# Save the figure as an HTML file in Colab's storage\n",
        "pyo.plot(fig_strict_final, filename='equity_curves.html', auto_open=False)\n",
        "\n",
        "print(\"🤠 Yeehaw! Your chart's been saved as 'equity_curves.html'. Go ahead and download it from the file pane on the left!\")\n"
      ],
      "metadata": {
        "id": "VfU5xKA31ON5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}